{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzarostmi/project_lightfm_suggest_Sahanuni/blob/main/projectfile_Algo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "from scipy.sparse import coo_matrix\n",
        "from lightfm import LightFM\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "\n",
        "\n",
        "#لاگر\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "if not logger.handlers:\n",
        "    fh = logging.FileHandler('lightfm_fast_scenarios.log')\n",
        "    ch = logging.StreamHandler(sys.stdout)\n",
        "    fmt = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(fmt)\n",
        "    ch.setFormatter(fmt)\n",
        "    logger.addHandler(fh)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "\n",
        "# 1) بارگذاری داده\n",
        "\n",
        "df = pd.read_csv('order-Product_prior.csv')\n",
        "\n",
        "# نسخه سریع\n",
        "df = df.head(50000)  # فقط ۵۰هزار رکورد\n",
        "\n",
        "# نسخه کامل و کند (اجرا طولانی ولی با دقت تخمین بالا) - در صورت نیاز فعال کنید\n",
        "# df = pd.read_csv('order-Product_prior.csv')\n",
        "\n",
        "df.columns = ['user_id', 'product_id', 'add_to_cart_order', 'reordered']\n",
        "df['rating'] = df['reordered'].fillna(0).clip(0, 1).astype(float)\n",
        "\n",
        "# نگاشت ID ها به ایندکس عددی\n",
        "user_ids = df['user_id'].unique()\n",
        "item_ids = df['product_id'].unique()\n",
        "user_map = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "item_map = {iid: idx for idx, iid in enumerate(item_ids)}\n",
        "\n",
        "df['u_idx'] = df['user_id'].map(user_map)\n",
        "df['i_idx'] = df['product_id'].map(item_map)\n",
        "\n",
        "# ساخت ماتریس تعاملات\n",
        "interactions = coo_matrix(\n",
        "    (df['rating'], (df['u_idx'], df['i_idx'])),\n",
        "    shape=(len(user_ids), len(item_ids))\n",
        ")\n",
        "logger.info(f\"ابعاد ماتریس تعاملات: {interactions.shape}\")\n",
        "\n",
        "\n",
        "# 2) تقسیم آموزش و تست\n",
        "\n",
        "train, test = random_train_test_split(\n",
        "    interactions, test_percentage=0.2, random_state=np.random.RandomState(42)\n",
        ")\n",
        "\n",
        "\n",
        "# 3) آموزش مدل\n",
        "\n",
        "# نسخه سریع\n",
        "model = LightFM(no_components=8, learning_rate=0.05, loss='warp')\n",
        "model.fit(train, epochs=5, num_threads=4)\n",
        "\n",
        "# نسخه کامل و کند (در صورت نیاز فعال کنید)\n",
        "# model = LightFM(no_components=32, learning_rate=0.05, loss='warp')\n",
        "# model.fit(train, epochs=20, num_threads=4)\n",
        "\n",
        "logger.info(\"مدل آموزش داده شد.\")\n",
        "\n",
        "\n",
        "# 4) تابع توصیه برای یک کاربر\n",
        "\n",
        "def recommend_for_user(model, train_mat, user_idx, n=5):\n",
        "    n_users, n_items = train_mat.shape\n",
        "    scores = model.predict(\n",
        "        np.repeat(user_idx, n_items),\n",
        "        np.arange(n_items),\n",
        "        num_threads=4\n",
        "    )\n",
        "    known_items = set(train_mat.tocsr()[user_idx].indices)\n",
        "    candidates = [i for i in range(n_items) if i not in known_items]\n",
        "    top_idx = np.argsort(-scores[candidates])[:n]\n",
        "    return [candidates[i] for i in top_idx], scores\n",
        "\n",
        "\n",
        "# 5) سناریوهای سه‌مرحله‌ای\n",
        "\n",
        "scenario_results = []\n",
        "target_user = df['u_idx'].iloc[0]\n",
        "user_all_items = set(train.tocsr()[target_user].indices) | set(test.tocsr()[target_user].indices)\n",
        "\n",
        "for remove_n in [1, 2, 3]:\n",
        "    if len(user_all_items) <= remove_n:\n",
        "        logger.warning(f\"کاربر آیتم کافی برای حذف {remove_n} ندارد.\")\n",
        "        continue\n",
        "\n",
        "    removed_items = list(user_all_items)[:remove_n]\n",
        "    train_mod = train.tolil(copy=True)\n",
        "    for it in removed_items:\n",
        "        train_mod[target_user, it] = 0.0\n",
        "\n",
        "    # نسخه سریع\n",
        "    model_mod = LightFM(no_components=8, learning_rate=0.05, loss='warp')\n",
        "    model_mod.fit(train_mod, epochs=5, num_threads=4)\n",
        "\n",
        "    # نسخه کامل و کند\n",
        "    # model_mod = LightFM(no_components=32, learning_rate=0.05, loss='warp')\n",
        "    # model_mod.fit(train_mod, epochs=20, num_threads=4)\n",
        "\n",
        "    top_items, scores = recommend_for_user(model_mod, train_mod, target_user, n=5)\n",
        "    correct_count = sum(1 for it in removed_items if it in top_items)\n",
        "    accuracy = correct_count / remove_n\n",
        "    logger.info(f\"سناریو حذف {remove_n} آیتم - دقت: {accuracy:.2f}\")\n",
        "\n",
        "    for it in top_items:\n",
        "        scenario_results.append({\n",
        "            'scenario': f'حذف {remove_n} آیتم',\n",
        "            'user_id': user_ids[target_user],\n",
        "            'product_id': item_ids[it],\n",
        "            'predicted_score': scores[it],\n",
        "            'is_target_item': item_ids[it] in [item_ids[x] for x in removed_items]\n",
        "        })\n",
        "\n",
        "pd.DataFrame(scenario_results).to_excel('scenario_results.xlsx', index=False)\n",
        "\n",
        "\n",
        "# 6) پیشنهاد برای همه کاربران\n",
        "\n",
        "def get_top_n_all_users(model, train_mat, user_map, item_map, n=5):\n",
        "    n_users, n_items = train_mat.shape\n",
        "    all_results = []\n",
        "    item_rev_map = {v: k for k, v in item_map.items()}\n",
        "    for uid, uidx in user_map.items():\n",
        "        scores = model.predict(np.repeat(uidx, n_items),\n",
        "                               np.arange(n_items),\n",
        "                               num_threads=4)\n",
        "        known_items = set(train_mat.tocsr()[uidx].indices)\n",
        "        candidates = [i for i in range(n_items) if i not in known_items]\n",
        "        top_idx = np.argsort(-scores[candidates])[:n]\n",
        "        for i in top_idx:\n",
        "            all_results.append({\n",
        "                'user_id': uid,\n",
        "                'product_id': item_rev_map[candidates[i]],\n",
        "                'predicted_score': scores[candidates[i]]\n",
        "            })\n",
        "    return all_results\n",
        "\n",
        "full_recs = get_top_n_all_users(model, train, user_map, item_map, n=5)\n",
        "pd.DataFrame(full_recs).to_excel('all_users_results.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "90isKwfn-sfL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}