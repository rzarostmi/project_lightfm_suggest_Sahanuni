{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzarostmi/project_lightfm_suggest_Sahanuni/blob/main/Copy_of_Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "from scipy.sparse import coo_matrix\n",
        "from lightfm import LightFM\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "\n",
        "\n",
        "#Ù„Ø§Ú¯Ø±\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "if not logger.handlers:\n",
        "    fh = logging.FileHandler('lightfm_fast_scenarios.log')\n",
        "    ch = logging.StreamHandler(sys.stdout)\n",
        "    fmt = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(fmt)\n",
        "    ch.setFormatter(fmt)\n",
        "    logger.addHandler(fh)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "\n",
        "# 1) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡\n",
        "\n",
        "df = pd.read_csv('order-Product_prior.csv')\n",
        "\n",
        "# Ù†Ø³Ø®Ù‡ Ø³Ø±ÛŒØ¹\n",
        "df = df.head(50000)  # ÙÙ‚Ø· ÛµÛ°Ù‡Ø²Ø§Ø± Ø±Ú©ÙˆØ±Ø¯\n",
        "\n",
        "# Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ Ùˆ Ú©Ù†Ø¯ (Ø§Ø¬Ø±Ø§ Ø·ÙˆÙ„Ø§Ù†ÛŒ ÙˆÙ„ÛŒ Ø¨Ø§ Ø¯Ù‚Øª ØªØ®Ù…ÛŒÙ† Ø¨Ø§Ù„Ø§) - Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯\n",
        "# df = pd.read_csv('order-Product_prior.csv')\n",
        "\n",
        "df.columns = ['user_id', 'product_id', 'add_to_cart_order', 'reordered']\n",
        "df['rating'] = df['reordered'].fillna(0).clip(0, 1).astype(float)\n",
        "\n",
        "# Ù†Ú¯Ø§Ø´Øª ID Ù‡Ø§ Ø¨Ù‡ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¹Ø¯Ø¯ÛŒ\n",
        "user_ids = df['user_id'].unique()\n",
        "item_ids = df['product_id'].unique()\n",
        "user_map = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "item_map = {iid: idx for idx, iid in enumerate(item_ids)}\n",
        "\n",
        "df['u_idx'] = df['user_id'].map(user_map)\n",
        "df['i_idx'] = df['product_id'].map(item_map)\n",
        "\n",
        "# Ø³Ø§Ø®Øª Ù…Ø§ØªØ±ÛŒØ³ ØªØ¹Ø§Ù…Ù„Ø§Øª\n",
        "interactions = coo_matrix(\n",
        "    (df['rating'], (df['u_idx'], df['i_idx'])),\n",
        "    shape=(len(user_ids), len(item_ids))\n",
        ")\n",
        "logger.info(f\"Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³ ØªØ¹Ø§Ù…Ù„Ø§Øª: {interactions.shape}\")\n",
        "\n",
        "\n",
        "# 2) ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª\n",
        "\n",
        "train, test = random_train_test_split(\n",
        "    interactions, test_percentage=0.2, random_state=np.random.RandomState(42)\n",
        ")\n",
        "\n",
        "\n",
        "# 3) Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
        "\n",
        "# Ù†Ø³Ø®Ù‡ Ø³Ø±ÛŒØ¹\n",
        "model = LightFM(no_components=8, learning_rate=0.05, loss='warp')\n",
        "model.fit(train, epochs=5, num_threads=4)\n",
        "\n",
        "# Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ Ùˆ Ú©Ù†Ø¯ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯)\n",
        "# model = LightFM(no_components=32, learning_rate=0.05, loss='warp')\n",
        "# model.fit(train, epochs=20, num_threads=4)\n",
        "\n",
        "logger.info(\"Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯.\")\n",
        "\n",
        "\n",
        "# 4) ØªØ§Ø¨Ø¹ ØªÙˆØµÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±\n",
        "\n",
        "def recommend_for_user(model, train_mat, user_idx, n=5):\n",
        "    n_users, n_items = train_mat.shape\n",
        "    scores = model.predict(\n",
        "        np.repeat(user_idx, n_items),\n",
        "        np.arange(n_items),\n",
        "        num_threads=4\n",
        "    )\n",
        "    known_items = set(train_mat.tocsr()[user_idx].indices)\n",
        "    candidates = [i for i in range(n_items) if i not in known_items]\n",
        "    top_idx = np.argsort(-scores[candidates])[:n]\n",
        "    return [candidates[i] for i in top_idx], scores\n",
        "\n",
        "\n",
        "# 5) Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø³Ù‡â€ŒÙ…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ\n",
        "\n",
        "scenario_results = []\n",
        "target_user = df['u_idx'].iloc[0]\n",
        "user_all_items = set(train.tocsr()[target_user].indices) | set(test.tocsr()[target_user].indices)\n",
        "\n",
        "for remove_n in [1, 2, 3]:\n",
        "    if len(user_all_items) <= remove_n:\n",
        "        logger.warning(f\"Ú©Ø§Ø±Ø¨Ø± Ø¢ÛŒØªÙ… Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù {remove_n} Ù†Ø¯Ø§Ø±Ø¯.\")\n",
        "        continue\n",
        "\n",
        "    removed_items = list(user_all_items)[:remove_n]\n",
        "    train_mod = train.tolil(copy=True)\n",
        "    for it in removed_items:\n",
        "        train_mod[target_user, it] = 0.0\n",
        "\n",
        "    # Ù†Ø³Ø®Ù‡ Ø³Ø±ÛŒØ¹\n",
        "    model_mod = LightFM(no_components=8, learning_rate=0.05, loss='warp')\n",
        "    model_mod.fit(train_mod, epochs=5, num_threads=4)\n",
        "\n",
        "    # Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ Ùˆ Ú©Ù†Ø¯\n",
        "    # model_mod = LightFM(no_components=32, learning_rate=0.05, loss='warp')\n",
        "    # model_mod.fit(train_mod, epochs=20, num_threads=4)\n",
        "\n",
        "    top_items, scores = recommend_for_user(model_mod, train_mod, target_user, n=5)\n",
        "    correct_count = sum(1 for it in removed_items if it in top_items)\n",
        "    accuracy = correct_count / remove_n\n",
        "    logger.info(f\"Ø³Ù†Ø§Ø±ÛŒÙˆ Ø­Ø°Ù {remove_n} Ø¢ÛŒØªÙ… - Ø¯Ù‚Øª: {accuracy:.2f}\")\n",
        "\n",
        "    for it in top_items:\n",
        "        scenario_results.append({\n",
        "            'scenario': f'Ø­Ø°Ù {remove_n} Ø¢ÛŒØªÙ…',\n",
        "            'user_id': user_ids[target_user],\n",
        "            'product_id': item_ids[it],\n",
        "            'predicted_score': scores[it],\n",
        "            'is_target_item': item_ids[it] in [item_ids[x] for x in removed_items]\n",
        "        })\n",
        "\n",
        "pd.DataFrame(scenario_results).to_excel('scenario_results.xlsx', index=False)\n",
        "\n",
        "\n",
        "# 6) Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†\n",
        "\n",
        "def get_top_n_all_users(model, train_mat, user_map, item_map, n=5):\n",
        "    n_users, n_items = train_mat.shape\n",
        "    all_results = []\n",
        "    item_rev_map = {v: k for k, v in item_map.items()}\n",
        "    for uid, uidx in user_map.items():\n",
        "        scores = model.predict(np.repeat(uidx, n_items),\n",
        "                               np.arange(n_items),\n",
        "                               num_threads=4)\n",
        "        known_items = set(train_mat.tocsr()[uidx].indices)\n",
        "        candidates = [i for i in range(n_items) if i not in known_items]\n",
        "        top_idx = np.argsort(-scores[candidates])[:n]\n",
        "        for i in top_idx:\n",
        "            all_results.append({\n",
        "                'user_id': uid,\n",
        "                'product_id': item_rev_map[candidates[i]],\n",
        "                'predicted_score': scores[candidates[i]]\n",
        "            })\n",
        "    return all_results\n",
        "\n",
        "full_recs = get_top_n_all_users(model, train, user_map, item_map, n=5)\n",
        "pd.DataFrame(full_recs).to_excel('all_users_results.xlsx', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90isKwfn-sfL",
        "outputId": "069fef60-2782-45a5-c92d-45d3f604b9f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:âœ… Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³: (4978, 11616)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:02,928 - INFO - âœ… Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯. Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø§ØªØ±ÛŒØ³: (4978, 11616)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:âœ… Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,026 - INFO - âœ… Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:ğŸ“Œ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø­Ø°Ù 1 Ø¢ÛŒØªÙ… â†’ Ø¯Ù‚Øª: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,263 - INFO - ğŸ“Œ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø­Ø°Ù 1 Ø¢ÛŒØªÙ… â†’ Ø¯Ù‚Øª: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:ğŸ“Œ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø­Ø°Ù 2 Ø¢ÛŒØªÙ… â†’ Ø¯Ù‚Øª: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,378 - INFO - ğŸ“Œ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø­Ø°Ù 2 Ø¢ÛŒØªÙ… â†’ Ø¯Ù‚Øª: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:ğŸ“Œ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø­Ø°Ù 3 Ø¢ÛŒØªÙ… â†’ Ø¯Ù‚Øª: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,487 - INFO - ğŸ“Œ Ø³Ù†Ø§Ø±ÛŒÙˆ Ø­Ø°Ù 3 Ø¢ÛŒØªÙ… â†’ Ø¯Ù‚Øª: 0.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}