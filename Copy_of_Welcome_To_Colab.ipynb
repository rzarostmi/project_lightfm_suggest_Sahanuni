{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzarostmi/project_lightfm_suggest_Sahanuni/blob/main/Copy_of_Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5KrEb6vrkR"
      },
      "source": [
        "# Welcome to Colab!\n",
        "\n",
        "\n",
        "## Access Popular LLMs via Google-Colab-AI Without an API Key\n",
        "Users with Colab's paid plans have free access to most popular LLMs via google-colab-ai Python library. For more details, refer to the [getting started with google colab ai](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Getting_started_with_google_colab_ai.ipynb).\n",
        "\n",
        "```\n",
        "from google.colab import ai\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)\n",
        "```\n",
        "\n",
        "\n",
        "## Explore the Gemini API\n",
        "The Gemini API gives you access to Gemini models created by Google DeepMind. Gemini models are built from the ground up to be multimodal, so you can reason seamlessly across text, images, code, and audio.\n",
        "\n",
        "**How to get started?**\n",
        "*  Go to [Google AI Studio](https://aistudio.google.com/) and log in with your Google account.\n",
        "*  [Create an API key](https://aistudio.google.com/app/apikey).\n",
        "* Use a quickstart for [Python](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started.ipynb), or call the REST API using [curl](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb).\n",
        "\n",
        "**Discover Gemini's advanced capabilities**\n",
        "*  Play with Gemini [multimodal outputs](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Image-out.ipynb), mixing text and images in an iterative way.\n",
        "*  Discover the [multimodal Live API](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI.ipynb ) (demo [here](https://aistudio.google.com/live)).\n",
        "*  Learn how to [analyze images and detect items in your pictures](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Spatial_understanding.ipynb\") using Gemini (bonus, there's a [3D version](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Spatial_understanding_3d.ipynb) as well!).\n",
        "*  Unlock the power of [Gemini thinking model](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_thinking.ipynb), capable of solving complex task with its inner thoughts.\n",
        "      \n",
        "**Explore complex use cases**\n",
        "*  Use [Gemini grounding capabilities](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb) to create a report on a company based on what the model can find on internet.\n",
        "*  Extract [invoices and form data from PDF](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb) in a structured way.\n",
        "*  Create [illustrations based on a whole book](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Book_illustration.ipynb) using Gemini large context window and Imagen.\n",
        "\n",
        "To learn more, check out the [Gemini cookbook](https://github.com/google-gemini/cookbook) or visit the [Gemini API documentation](https://ai.google.dev/docs/).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "from scipy.sparse import coo_matrix\n",
        "from lightfm import LightFM\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "\n",
        "# ---------------------\n",
        "# تنظیمات لاگ فارسی\n",
        "# ---------------------\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "if not logger.handlers:\n",
        "    fh = logging.FileHandler('lightfm_fast_scenarios.log')\n",
        "    ch = logging.StreamHandler(sys.stdout)\n",
        "    fmt = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    fh.setFormatter(fmt)\n",
        "    ch.setFormatter(fmt)\n",
        "    logger.addHandler(fh)\n",
        "    logger.addHandler(ch)\n",
        "\n",
        "# ---------------------\n",
        "# 1) بارگذاری داده\n",
        "# ---------------------\n",
        "df = pd.read_csv('/content/order-Product_prior.csv')\n",
        "\n",
        "# 🔹 نسخه سریع (برای تست)\n",
        "df = df.head(50000)  # فقط ۵۰هزار ردیف اول\n",
        "\n",
        "# 🔹 نسخه کامل و کند (کامنت شده)\n",
        "# df = pd.read_csv('order-Product_prior.csv')  # کل داده\n",
        "# (توجه: فعال‌کردن این خط و حذف head(...) باعث اجرای کامل و طولانی‌تر می‌شود)\n",
        "\n",
        "df.columns = ['user_id', 'product_id', 'add_to_cart_order', 'reordered']\n",
        "df['rating'] = df['reordered'].fillna(0).clip(0, 1).astype(float)\n",
        "\n",
        "# نگاشت IDها به اندیس\n",
        "user_ids = df['user_id'].unique()\n",
        "item_ids = df['product_id'].unique()\n",
        "user_map = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "item_map = {iid: idx for idx, iid in enumerate(item_ids)}\n",
        "\n",
        "df['u_idx'] = df['user_id'].map(user_map)\n",
        "df['i_idx'] = df['product_id'].map(item_map)\n",
        "\n",
        "interactions = coo_matrix((df['rating'], (df['u_idx'], df['i_idx'])),\n",
        "                          shape=(len(user_ids), len(item_ids)))\n",
        "logger.info(f\"✅ داده بارگذاری شد. ابعاد ماتریس: {interactions.shape}\")\n",
        "\n",
        "# ---------------------\n",
        "# 2) تقسیم آموزش/تست\n",
        "# ---------------------\n",
        "train, test = random_train_test_split(interactions, test_percentage=0.2,\n",
        "                                      random_state=np.random.RandomState(42))\n",
        "\n",
        "# ---------------------\n",
        "# 3) آموزش مدل\n",
        "# ---------------------\n",
        "# 🔹 نسخه سریع\n",
        "model = LightFM(no_components=8, learning_rate=0.05, loss='warp')\n",
        "model.fit(train, epochs=5, num_threads=4)\n",
        "\n",
        "# 🔹 نسخه کامل و کند (کامنت شده)\n",
        "# model = LightFM(no_components=32, learning_rate=0.05, loss='warp')\n",
        "# model.fit(train, epochs=20, num_threads=4)\n",
        "\n",
        "logger.info(\"✅ مدل آموزش داده شد.\")\n",
        "\n",
        "# ---------------------\n",
        "# 4) تابع توصیه برای یک کاربر\n",
        "# ---------------------\n",
        "def recommend_for_user(model, train_mat, user_idx, n=5):\n",
        "    n_users, n_items = train_mat.shape\n",
        "    scores = model.predict(\n",
        "        np.repeat(user_idx, n_items),\n",
        "        np.arange(n_items),\n",
        "        num_threads=4\n",
        "    )\n",
        "    known_items = set(train_mat.tocsr()[user_idx].indices)\n",
        "    candidates = [i for i in range(n_items) if i not in known_items]\n",
        "    top_idx = np.argsort(-scores[candidates])[:n]\n",
        "    return [candidates[i] for i in top_idx], scores\n",
        "\n",
        "# ---------------------\n",
        "# 5) اجرای سناریوها (برای یک کاربر نمونه)\n",
        "# ---------------------\n",
        "scenario_results = []\n",
        "target_user = df['u_idx'].iloc[0]\n",
        "user_all_items = set(train.tocsr()[target_user].indices) | set(test.tocsr()[target_user].indices)\n",
        "\n",
        "for remove_n in [1, 2, 3]:\n",
        "    if len(user_all_items) <= remove_n:\n",
        "        logger.warning(f\"کاربر آیتم کافی برای حذف {remove_n} ندارد.\")\n",
        "        continue\n",
        "\n",
        "    removed_items = list(user_all_items)[:remove_n]\n",
        "    train_mod = train.tolil(copy=True)\n",
        "    for it in removed_items:\n",
        "        train_mod[target_user, it] = 0.0\n",
        "\n",
        "    # 🔹 نسخه سریع\n",
        "    model_mod = LightFM(no_components=8, learning_rate=0.05, loss='warp')\n",
        "    model_mod.fit(train_mod, epochs=5, num_threads=4)\n",
        "\n",
        "    # 🔹 نسخه کامل و کند (کامنت شده)\n",
        "    # model_mod = LightFM(no_components=32, learning_rate=0.05, loss='warp')\n",
        "    # model_mod.fit(train_mod, epochs=20, num_threads=4)\n",
        "\n",
        "    top_items, scores = recommend_for_user(model_mod, train_mod, target_user, n=5)\n",
        "    correct_count = sum(1 for it in removed_items if it in top_items)\n",
        "    accuracy = correct_count / remove_n\n",
        "    logger.info(f\"📌 سناریو حذف {remove_n} آیتم → دقت: {accuracy:.2f}\")\n",
        "\n",
        "    for it in top_items:\n",
        "        scenario_results.append({\n",
        "            'scenario': f'حذف {remove_n} آیتم',\n",
        "            'user_id': user_ids[target_user],\n",
        "            'product_id': item_ids[it],\n",
        "            'predicted_score': scores[it],\n",
        "            'is_target_item': item_ids[it] in [item_ids[x] for x in removed_items]\n",
        "        })\n",
        "\n",
        "pd.DataFrame(scenario_results).to_excel('scenario_results.xlsx', index=False)\n",
        "\n",
        "# ---------------------\n",
        "# 6) پیشنهاد برای همه کاربران\n",
        "# ---------------------\n",
        "def get_top_n_all_users(model, train_mat, user_map, item_map, n=5):\n",
        "    n_users, n_items = train_mat.shape\n",
        "    all_results = []\n",
        "    item_rev_map = {v: k for k, v in item_map.items()}\n",
        "    for uid, uidx in user_map.items():\n",
        "        scores = model.predict(np.repeat(uidx, n_items),\n",
        "                               np.arange(n_items),\n",
        "                               num_threads=4)\n",
        "        known_items = set(train_mat.tocsr()[uidx].indices)\n",
        "        candidates = [i for i in range(n_items) if i not in known_items]\n",
        "        top_idx = np.argsort(-scores[candidates])[:n]\n",
        "        for i in top_idx:\n",
        "            all_results.append({\n",
        "                'user_id': uid,\n",
        "                'product_id': item_rev_map[candidates[i]],\n",
        "                'predicted_score': scores[candidates[i]]\n",
        "            })\n",
        "    return all_results\n",
        "\n",
        "full_recs = get_top_n_all_users(model, train, user_map, item_map, n=5)\n",
        "pd.DataFrame(full_recs).to_excel('all_users_results.xlsx', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90isKwfn-sfL",
        "outputId": "069fef60-2782-45a5-c92d-45d3f604b9f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:✅ داده بارگذاری شد. ابعاد ماتریس: (4978, 11616)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:02,928 - INFO - ✅ داده بارگذاری شد. ابعاد ماتریس: (4978, 11616)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:✅ مدل آموزش داده شد.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,026 - INFO - ✅ مدل آموزش داده شد.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:📌 سناریو حذف 1 آیتم → دقت: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,263 - INFO - 📌 سناریو حذف 1 آیتم → دقت: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:📌 سناریو حذف 2 آیتم → دقت: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,378 - INFO - 📌 سناریو حذف 2 آیتم → دقت: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:📌 سناریو حذف 3 آیتم → دقت: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-19 17:12:03,487 - INFO - 📌 سناریو حذف 3 آیتم → دقت: 0.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}